import os
import json
from dotenv import load_dotenv

try:
    import chromadb
    from chromadb import Documents, EmbeddingFunction, Embeddings
    CHROMADB_AVAILABLE = True
except Exception as e:
    print("[WARN] chromadb not available:", e)
    chromadb = None
    CHROMADB_AVAILABLE = False

from anthropic import Anthropic

try:
    import cohere
    COHERE_AVAILABLE = True
except Exception as e:
    print("[WARN] cohere not available:", e)
    cohere = None
    COHERE_AVAILABLE = False

from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from src.utils.logger import AgentLogger

load_dotenv()
VERBOSE_MODE = os.getenv("VERBOSE", "True").lower() == "true"

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

if os.path.exists("/opt/render/project"):
    CHROMA_DB_DIR = "/opt/render/project/chroma_db"
    print(f"[CONFIG] Using Render persistent disk: {CHROMA_DB_DIR}")
else:
    CHROMA_DB_DIR = os.path.join(BASE_DIR, "chroma_db")
    # Check if temp DB exists (from fresh ingestion), use that
    temp_db = os.path.join(BASE_DIR, "chroma_db_temp")
    if os.path.exists(temp_db) and not os.path.exists(CHROMA_DB_DIR):
        CHROMA_DB_DIR = temp_db
        print(f"[CONFIG] Using fresh ChromaDB from ingestion: {CHROMA_DB_DIR}")
    else:
        print(f"[CONFIG] Using local disk: {CHROMA_DB_DIR}")

logger = AgentLogger(verbose=VERBOSE_MODE)

# ‚îÄ‚îÄ Clients ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")
claude_client = None
if anthropic_api_key:
    try:
        claude_client = Anthropic(api_key=anthropic_api_key)
    except Exception as e:
        print("[WARN] Failed to initialize Anthropic client:", e)
else:
    print("WARNING: ANTHROPIC_API_KEY not found.")

cohere_api_key = os.getenv("COHERE_API_KEY")
co_client = None
if not COHERE_AVAILABLE:
    print("WARNING: Cohere library unavailable.")
elif not cohere_api_key:
    print("WARNING: COHERE_API_KEY not found.")
else:
    co_client = cohere.Client(api_key=cohere_api_key)

# ‚îÄ‚îÄ ChromaDB ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

if CHROMADB_AVAILABLE:
    class CohereEmbeddingFunction(EmbeddingFunction):
        def __init__(self, client):
            self.client = client
        def __call__(self, input: Documents) -> Embeddings:
            if not self.client:
                return [[0.0] for _ in input]
            response = self.client.embed(
                texts=input,
                model="embed-multilingual-v3.0",
                input_type="search_query"
            )
            return response.embeddings
else:
    class CohereEmbeddingFunction:
        def __init__(self, client):
            self.client = client
        def __call__(self, input):
            return [[0.0] for _ in input]

collection = None
print(f"Connecting to Database at: {CHROMA_DB_DIR}...")
if CHROMADB_AVAILABLE and co_client is not None:
    try:
        chroma_client = chromadb.PersistentClient(path=CHROMA_DB_DIR)
        embedding_fn = CohereEmbeddingFunction(co_client)
        collection = chroma_client.get_or_create_collection(
            name="math_curriculum_benin",
            embedding_function=embedding_fn
        )
    except Exception as e:
        print("[WARN] Failed to initialize ChromaDB:", e)
else:
    print("[WARN] ChromaDB or Cohere not available ‚Äî search disabled.")

# ‚îÄ‚îÄ Prompts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

IMAGE_OCR_PROMPT = """Transcribe EVERYTHING visible in this image with complete accuracy.

Include ALL of the following if present:
- Every word of text, exactly as written
- All mathematical expressions, equations, and formulas (use standard LaTeX notation)
- Numbers, variables, symbols, operators, indices, exponents
- Diagrams described precisely in words (e.g. "Triangle ABC with angle A = 30¬∞, BC = 5cm")
- Table contents row by row with headers
- Any labels, captions, units, annotations
- Instructions, question numbers, and sub-parts (a), b), c)...)

Output ONLY the raw transcribed content. No commentary, no "I see...", no preamble."""

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SYSTEM PROMPT ‚Äî concise tutoring style
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

SYSTEM_PROMPT = """Tu es **Professeur Bio**, un tuteur IA sp√©cialis√© **UNIQUEMENT en math√©matiques** pour les √©tudiants de l'Universit√© du B√©nin (L1/L2).

## ‚ö†Ô∏è CONTRAINTE ABSOLUE : MATH√âMATIQUES UNIQUEMENT
**Tu DOIS refuser** toute question qui n'est PAS directement li√©e aux math√©matiques :
- ‚ùå Sciences g√©n√©rales, biologie, physique, chimie (sauf si application math√©matique)
- ‚ùå Questions g√©n√©rales, histoire, politique, technologie
- ‚ùå Conseils de vie, sant√©, philosophie
- ‚úÖ **ACCEPTE SEULEMENT** : alg√®bre, g√©om√©trie, calcul, polyn√¥mes, structures alg√©briques, trigonom√©trie, etc.

Si la question n'est PAS de math√©matiques, r√©ponds EXACTEMENT ceci :
```
D√©sol√©, je suis sp√©cialis√© uniquement en math√©matiques. Peux-tu me poser une question de maths ? 
Ex: structures alg√©briques, calcul, g√©om√©trie, √©quations, etc.
```

## STYLE : CONCIS, CLAIR, √âTAPE PAR √âTAPE
- **R√©ponse courte** : 3-5 phrases maximum (2-3 si c'est simple).
- **Structure l√©g√®re** : √ânonce le concept, puis 1-2 √©tapes cl√©s, puis la conclusion.
- **Pas de blabla** : Va droit au but.
- **LaTeX inline** : $formule$ pour les math√©matiques courtes.

## PRIORIT√â : CONSULTATION DES RESSOURCES
**AVANT de r√©pondre** :
1. **Cherche dans le contexte fourni** (curriculum math√©matique du B√©nin).
2. **Si contexte pertinent trouv√©** ‚Üí utilise-le ET cite la source (ex: "Voir MTH1220, p.15").
3. **Si aucun contexte** ‚Üí r√©ponds avec tes connaissances math√©matiques.

## INSTRUCTIONS PAR CAS

**Question simple** : 
- 1 phrase r√©ponse
- 1 ligne explication

**Probl√®me** :
- **√âtape 1** : [concept cl√©]
- **√âtape 2** : [suite logique]
- **R√©ponse** : [r√©sultat]

**Concept** :
- D√©finition rapide
- 1 exemple concret

## CE QU'IL NE FAUT PAS FAIRE
- ‚ùå Listes longues, titres multiples, sections inutiles
- ‚ùå R√©ponses longues (max 3-5 lignes)
- ‚ùå R√©pondre √† des questions NON-math√©matiques"""

# ‚îÄ‚îÄ Tutor prompt template ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

TUTOR_PROMPT = """## CONTEXTE DU PROGRAMME
{context_str}

---
{image_section}
## QUESTION
{question}

---
R√©ponds de fa√ßon **courte et claire**. Si le contexte est pertinent, utilise-le. Sinon, r√©ponds avec tes connaissances.
{image_recap_instruction}
Donne la r√©ponse directement, avec les formules LaTeX n√©cessaires. Sois concis."""

# ‚îÄ‚îÄ Tools ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def search_curriculum(query: str) -> tuple[str, list]:
    """Search ChromaDB for relevant curriculum content."""
    if collection is None:
        logger.log_step("Warning", "ChromaDB not available ‚Äî skipping search")
        return "", []

    logger.log_step("Action", f"Searching ChromaDB for: '{query[:80]}'")
    try:
        results = collection.query(query_texts=[query], n_results=4)
        documents = results["documents"][0]
        metadatas = results["metadatas"][0]
        distances = results.get("distances", [[]])[0]
    except Exception as e:
        print(f"[WARN] ChromaDB query failed: {e}")
        return "", []

    context_text = ""
    sources = []

    for i, doc in enumerate(documents):
        meta = metadatas[i]
        source = meta.get("source", "Unknown")
        page = meta.get("page", "?")
        distance = distances[i] if distances else None

        if distance is not None and distance > 1.5:
            print(f"[SEARCH] Skipping low-relevance result (distance={distance:.3f}): {source}")
            continue

        context_text += f"\n--- {source} (p.{page}) ---\n{doc}\n"
        sources.append({"text": doc, "source": source, "page": page})

    if not context_text.strip():
        print("[SEARCH] No relevant curriculum content found for this query.")

    return context_text, sources


def extract_image_content(attachment: dict) -> tuple[str, str, str]:
    """
    OCR the uploaded image via Claude vision.
    Returns: (raw_text, image_section_for_prompt, image_recap_instruction)
    """
    if not attachment or not claude_client:
        return "", "", ""

    image_payload = None
    if isinstance(attachment, dict):
        image_payload = attachment.get("image")
        if image_payload is None and attachment.get("type") and attachment.get("image"):
            image_payload = attachment

    if not image_payload:
        return "", "", ""

    logger.log_step("Action", "Running OCR on uploaded image...")
    try:
        response = claude_client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=1500,
            messages=[{
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": image_payload.get("type"),
                            "data": image_payload.get("image"),
                        },
                    },
                    {"type": "text", "text": IMAGE_OCR_PROMPT}
                ],
            }]
        )
        extracted = response.content[0].text.strip()
    except Exception as e:
        print(f"[WARN] OCR failed: {e}")
        return "", "", ""

    logger.log_step("Observation", f"OCR: {len(extracted)} chars ‚Äî {extracted[:100]}...")

    image_section = f"""## üì∑ CONTENU DE L'IMAGE (OCR)
```
{extracted}
```
"""
    image_recap_instruction = (
        "Si une image est fournie, commence par une ligne confirmant ce que tu as lu "
        "dans l'image (ex : ¬´ J'ai bien lu : [r√©sum√© du probl√®me] ¬ª), puis r√©sous directement."
    )

    return extracted, image_section, image_recap_instruction


def extract_document_content(attachment: dict) -> tuple[str, str]:
    if not attachment or not isinstance(attachment, dict):
        return "", ""
    document_text = attachment.get("document_text") or ""
    if not document_text:
        return "", ""
    document_section = f"""## üìÑ CONTENU DU DOCUMENT
```
{document_text}
```
"""
    return document_text, document_section


def _build_prompt(
    question: str,
    context_observation: str,
    image_section: str,
    image_recap_instruction: str,
) -> str:
    """Assemble the user-turn prompt."""
    if not image_recap_instruction:
        image_recap_instruction = ""

    return TUTOR_PROMPT.format(
        context_str=context_observation if context_observation.strip() else "Aucun contenu pertinent trouv√©.",
        question=question,
        image_section=image_section,
        image_recap_instruction=image_recap_instruction,
    )


# ‚îÄ‚îÄ Main orchestrator ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def ask_math_ai(question: str, history: str = "", attachment=None) -> dict:
    logger.log_step("Thought", f"Processing: {question[:80]}")
    execution_steps = []

    image_section = ""
    document_section = ""
    image_recap_instruction = ""
    search_query = question

    if attachment:
        img_text, image_section, image_recap_instruction = extract_image_content(attachment)
        doc_text, document_section = extract_document_content(attachment)
        if img_text:
            search_query = (search_query + "\n" + img_text).strip() if search_query.strip() else img_text
        if doc_text:
            search_query = (search_query + "\n" + doc_text).strip() if search_query.strip() else doc_text

    if document_section and image_section:
        image_section = f"{image_section}\n{document_section}"
    elif document_section:
        image_section = document_section

    context_observation, sources = search_curriculum(search_query)

    if claude_client is None:
        return {
            "partie": "Erreur", "problemStatement": question,
            "steps": [{"title": "Unavailable",
                        "explanation": "ANTHROPIC_API_KEY non configur√©.", "equations": None}],
            "conclusion": None, "sources": []
        }

    if context_observation.strip():
        logger.log_step("Observation", f"Context found ({len(context_observation)} chars)")
        execution_steps.append({"type": "observation", "content": "Context retrieved"})
    else:
        logger.log_step("Observation", "No relevant context ‚Äî model will use general knowledge")

    prompt = _build_prompt(question, context_observation, image_section, image_recap_instruction)

    try:
        resp = claude_client.messages.create(
            model="claude-sonnet-4-5",
            max_tokens=3000,
            system=SYSTEM_PROMPT,
            messages=[{"role": "user", "content": prompt}]
        )
        final_answer = resp.content[0].text

        logger.save_request(
            prompt=question, model="claude-sonnet-4.5",
            steps=execution_steps, final_answer=final_answer,
            verifier_result="Passed", confidence=1.0
        )

        return {
            "partie": "Math√©matiques / Physique",
            "problemStatement": question,
            "steps": [{"title": "Explication Professeur Bio",
                        "explanation": final_answer, "equations": None}],
            "conclusion": "Voir explication ci-dessus",
            "sources": sources
        }
    except Exception as e:
        error_msg = f"Erreur Claude: {e}"
        logger.log_step("Error", error_msg)
        return {
            "partie": "Erreur", "problemStatement": question,
            "steps": [{"title": "Erreur", "explanation": error_msg, "equations": None}],
            "conclusion": None, "sources": []
        }


def ask_math_ai_stream(question: str, history: str = "", attachment=None):
    """Streaming version ‚Äî yields NDJSON: metadata / token / done / error."""
    logger.log_step("Thought", f"Processing (stream): {question[:80]}")
    execution_steps = []

    image_section = ""
    document_section = ""
    image_recap_instruction = ""
    search_query = question

    if attachment:
        img_text, image_section, image_recap_instruction = extract_image_content(attachment)
        doc_text, document_section = extract_document_content(attachment)
        if img_text:
            search_query = (search_query + "\n" + img_text).strip() if search_query.strip() else img_text
            logger.log_step("Observation", f"OCR done, search query: {search_query[:100]}")
        if doc_text:
            search_query = (search_query + "\n" + doc_text).strip() if search_query.strip() else doc_text
            logger.log_step("Observation", f"Document parsed, search query: {search_query[:100]}")

    if document_section and image_section:
        image_section = f"{image_section}\n{document_section}"
    elif document_section:
        image_section = document_section

    context_observation, sources = search_curriculum(search_query)

    if claude_client is None:
        yield json.dumps({"error": "ANTHROPIC_API_KEY non configur√©."}) + "\n"
        return

    if context_observation.strip():
        logger.log_step("Observation", f"Context found ({len(context_observation)} chars)")
        execution_steps.append({"type": "observation", "content": "Context retrieved"})
    else:
        logger.log_step("Observation", "No relevant context ‚Äî model will use general knowledge")

    prompt = _build_prompt(question, context_observation, image_section, image_recap_instruction)

    try:
        yield json.dumps({
            "metadata": {
                "partie": "Math√©matiques / Physique",
                "problemStatement": question,
                "sources": sources
            }
        }) + "\n"

        full_response = ""
        with claude_client.messages.stream(
            model="claude-sonnet-4-5",
            max_tokens=3000,
            system=SYSTEM_PROMPT,
            messages=[{"role": "user", "content": prompt}]
        ) as stream:
            for text in stream.text_stream:
                full_response += text
                yield json.dumps({"token": text}) + "\n"

        yield json.dumps({
            "done": True,
            "conclusion": "Voir explication ci-dessus",
            "sources": sources
        }) + "\n"

        logger.save_request(
            prompt=question, model="claude-sonnet-4.5-stream",
            steps=execution_steps, final_answer=full_response,
            verifier_result="Passed", confidence=1.0
        )

    except Exception as e:
        error_msg = f"Erreur Claude: {e}"
        logger.log_step("Error", error_msg)
        yield json.dumps({"error": error_msg}) + "\n"


# ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

console = Console()

if __name__ == "__main__":
    user_query = "D√©montrer que la fonction f(x) = x¬≤ est d√©rivable en tout point de ‚Ñù."
    result = ask_math_ai(user_query)
    main_text = result["steps"][0]["explanation"] if result.get("steps") else "Pas de r√©ponse."
    console.print(Panel(
        Markdown(main_text),
        title="PROFESSEUR BIO",
        subtitle="Claude Sonnet 4.5 ‚Äî MTH1122/MTH1220/PHY1223",
        border_style="green"
    ))
    if result.get("sources"):
        for i, src in enumerate(result["sources"]):
            console.print(f"[cyan]{i+1}. {src['source']} (p.{src['page']})[/cyan]")
